# ë°°ë‹¬ì˜ë¯¼ì¡± ë°ì´í„° ë¶„ì„ í† ì´í”„ë¡œì íŠ¸ ê°€ì´ë“œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ë°°ë‹¬ì˜ë¯¼ì¡±ì˜ ì‹¤ì œ ê³ ê° ì£¼ë¬¸ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì˜ ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì„ ì²´í—˜í•´ë³´ëŠ” í† ì´í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. Kafka, Airflow, Redis, Kubernetes, AWS ë“± ì‹¤ì œ ê¸°ì—…ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ  ìŠ¤íƒì„ í™œìš©í•˜ì—¬ ì—”ë“œíˆ¬ì—”ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ

1. **ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ê²½í—˜**: 10ë§Œê±´ì˜ ì‹¤ì œ ë°°ë‹¬ ë°ì´í„°ë¥¼ ë‹¤ë£¨ë©° ë°ì´í„° ì „ì²˜ë¦¬, ë¶„ì„, ì‹œê°í™” ê²½í—˜
2. **í˜„ëŒ€ì  ê¸°ìˆ  ìŠ¤íƒ ìŠµë“**: Kafka, Airflow, Redis, Docker, Kubernetes, AWS ë“± ì‹¤ì œ ê¸°ì—…ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ ë“¤
3. **ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**: ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ì›¹ ì„œë¹„ìŠ¤ ë°°í¬ê¹Œì§€ ì „ì²´ ê³¼ì • ì´í•´
4. **í´ë¼ìš°ë“œ ë°°í¬ ê²½í—˜**: AWSë¥¼ í†µí•œ ì‹¤ì œ ì„œë¹„ìŠ¤ ë°°í¬ ë° ìš´ì˜ ê²½í—˜

## ğŸ“Š ë°ì´í„° ì†Œê°œ

### ì œê³µëœ ë°ì´í„° íŒŒì¼ë“¤
- `ë°°ë‹¬ì˜ë¯¼ì¡±_ê°€ëª…ë°ì´í„°_10ë§Œê±´.csv` (39MB): ì£¼ìš” ì£¼ë¬¸ ë°ì´í„°
- `ë°°ë‹¬ì˜ë¯¼ì¡±_ë©”ì‹œì§€_ë°ì´í„°_25000ê±´.json` (33MB): ê³ ê°-ê°€ê²Œ ê°„ ë©”ì‹œì§€ ë°ì´í„°
- `ë°°ë‹¬ì˜ë¯¼ì¡±_JSON_ë°ì´í„°_25000ê±´.json` (32MB): JSON í˜•íƒœì˜ ì£¼ë¬¸ ë°ì´í„°
- `ë°°ë‹¬ì˜ë¯¼ì¡±_XML_ë°ì´í„°_25000ê±´.xml` (25MB): XML í˜•íƒœì˜ ì£¼ë¬¸ ë°ì´í„°
- `ë°°ë‹¬ì˜ë¯¼ì¡±_ë¡œê·¸_ë°ì´í„°_25000ê±´.log` (4.3MB): ì‹œìŠ¤í…œ ë¡œê·¸ ë°ì´í„°
- `ë°°ë‹¬ì˜ë¯¼ì¡±_í†µí•©_ë¹„ì •í˜•ë°ì´í„°_10ë§Œê±´.pickle` (55MB): í†µí•©ëœ ë¹„ì •í˜• ë°ì´í„°

### ì˜ˆìƒ ë°ì´í„° êµ¬ì¡°
- **ì£¼ë¬¸ ì •ë³´**: ì£¼ë¬¸ ì‹œê°„, ë°°ë‹¬ ì£¼ì†Œ, ì£¼ë¬¸ ê¸ˆì•¡, ë©”ë‰´ ì •ë³´
- **ê³ ê° ì •ë³´**: ê³ ê° ID, ì„ í˜¸ ë©”ë‰´, ì£¼ë¬¸ íŒ¨í„´
- **ê°€ê²Œ ì •ë³´**: ê°€ê²Œ ID, ë©”ë‰´ ì¹´í…Œê³ ë¦¬, í‰ì 
- **ë°°ë‹¬ ì •ë³´**: ë°°ë‹¬ ì‹œê°„, ë°°ë‹¬ ê±°ë¦¬, ë°°ë‹¬ë£Œ
- **ë©”ì‹œì§€ ë°ì´í„°**: ê³ ê°-ê°€ê²Œ ê°„ ì†Œí†µ ë‚´ìš©

## ğŸ—ï¸ í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜

```
[ë°ì´í„° ì†ŒìŠ¤] â†’ [Kafka] â†’ [Airflow] â†’ [Redis/PostgreSQL] â†’ [ì›¹ ì„œë¹„ìŠ¤] â†’ [Kubernetes] â†’ [AWS]
```

### 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ë° ìŠ¤íŠ¸ë¦¬ë° (Kafka)
### 2ë‹¨ê³„: ë°ì´í„° ì²˜ë¦¬ ë° ì •ë¦¬ (Airflow)
### 3ë‹¨ê³„: ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬ (Redis + PostgreSQL)
### 4ë‹¨ê³„: ì›¹ ì„œë¹„ìŠ¤ ê°œë°œ (Flask/FastAPI)
### 5ë‹¨ê³„: ì»¨í…Œì´ë„ˆí™” (Docker)
### 6ë‹¨ê³„: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Kubernetes)
### 7ë‹¨ê³„: í´ë¼ìš°ë“œ ë°°í¬ (AWS)

## ğŸ“ ìƒì„¸ ì§„í–‰ ë‹¨ê³„

### Phase 1: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° íƒìƒ‰ (1-2ì£¼)

#### 1.1 Windows ê°œë°œ í™˜ê²½ êµ¬ì¶•
```bash
# 1. Python ê°€ìƒí™˜ê²½ ìƒì„± (Windows)
python -m venv delivery_project
delivery_project\Scripts\activate

# 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install pandas numpy matplotlib seaborn plotly
pip install kafka-python apache-airflow
pip install flask fastapi uvicorn
pip install docker kubernetes
pip install boto3  # AWS SDK
pip install redis psycopg2-binary  # Redis, PostgreSQL
pip install beautifulsoup4 lxml  # XML íŒŒì‹±
```

#### 1.2 ë¹„ì •í˜• ë°ì´í„° ì¶”ì¶œ ë„êµ¬ ì„¤ì¹˜
```bash
# ë°ì´í„° ì¶”ì¶œ ê´€ë ¨ íŒ¨í‚¤ì§€
pip install openpyxl xlrd  # Excel íŒŒì¼ ì²˜ë¦¬
pip install PyPDF2 pdfplumber  # PDF íŒŒì¼ ì²˜ë¦¬
pip install requests  # API í˜¸ì¶œ
pip install selenium  # ì›¹ ìŠ¤í¬ë˜í•‘
```

#### 1.3 ë°ì´í„° íƒìƒ‰ ë° ë¶„ì„ (EDA)
```python
# ì˜ˆì‹œ ì½”ë“œ
import pandas as pd
import json
import xml.etree.ElementTree as ET

# CSV ë°ì´í„° ë¡œë“œ
df_orders = pd.read_csv('data/ë°°ë‹¬ì˜ë¯¼ì¡±_ê°€ëª…ë°ì´í„°_10ë§Œê±´.csv')

# JSON ë°ì´í„° ë¡œë“œ
with open('data/ë°°ë‹¬ì˜ë¯¼ì¡±_ë©”ì‹œì§€_ë°ì´í„°_25000ê±´.json', 'r') as f:
    messages_data = json.load(f)

# ê¸°ë³¸ í†µê³„ ë¶„ì„
print("ë°ì´í„° í¬ê¸°:", df_orders.shape)
print("ì»¬ëŸ¼ ì •ë³´:", df_orders.columns.tolist())
print("ê²°ì¸¡ê°’ í™•ì¸:", df_orders.isnull().sum())
```

**ë¶„ì„í•´ì•¼ í•  ì£¼ìš” ë‚´ìš©:**
- ë°ì´í„° í’ˆì§ˆ í™•ì¸ (ê²°ì¸¡ê°’, ì´ìƒì¹˜, ì¤‘ë³µê°’)
- ê¸°ë³¸ í†µê³„ ë¶„ì„ (í‰ê· , ë¶„ì‚°, ë¶„í¬)
- ì‹œê°í™”ë¥¼ í†µí•œ íŒ¨í„´ ë°œê²¬
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

#### 1.4 ë°ì´í„° ì „ì²˜ë¦¬ ê³„íš ìˆ˜ë¦½
- **ë°ì´í„° í´ë¦¬ë‹**: ê²°ì¸¡ê°’ ì²˜ë¦¬, ì´ìƒì¹˜ ì œê±°, ë°ì´í„° íƒ€ì… ë³€í™˜
- **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: ì‹œê°„ëŒ€ë³„ ë¶„ì„, ì§€ì—­ë³„ ë¶„ì„, ê³ ê° ì„¸ë¶„í™”
- **ë°ì´í„° í†µí•©**: ì—¬ëŸ¬ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í†µí•©

### Phase 2: Kafka ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (1ì£¼)

#### 2.1 Kafka í™˜ê²½ ì„¤ì • (Windows)
```bash
# Docker Desktop for Windows ì„¤ì¹˜ í›„
docker-compose up -d zookeeper kafka
```

#### 2.2 ë°ì´í„° í”„ë¡œë“€ì„œ ê°œë°œ
```python
# ì˜ˆì‹œ ì½”ë“œ
from kafka import KafkaProducer
import json
import pandas as pd

def create_producer():
    return KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda x: json.dumps(x).encode('utf-8')
    )

def send_order_data():
    producer = create_producer()
    df = pd.read_csv('data/ë°°ë‹¬ì˜ë¯¼ì¡±_ê°€ëª…ë°ì´í„°_10ë§Œê±´.csv')
    
    for _, row in df.iterrows():
        message = {
            'order_id': row['order_id'],
            'customer_id': row['customer_id'],
            'restaurant_id': row['restaurant_id'],
            'order_amount': row['order_amount'],
            'order_time': row['order_time']
        }
        producer.send('delivery_orders', message)
    
    producer.flush()
```

#### 2.3 ë°ì´í„° ì»¨ìŠˆë¨¸ ê°œë°œ
```python
from kafka import KafkaConsumer
import json

def create_consumer():
    return KafkaConsumer(
        'delivery_orders',
        bootstrap_servers=['localhost:9092'],
        value_deserializer=lambda x: json.loads(x.decode('utf-8'))
    )

def process_messages():
    consumer = create_consumer()
    for message in consumer:
        # ë°ì´í„° ì²˜ë¦¬ ë¡œì§
        process_order_data(message.value)
```

### Phase 3: Airflow ì›Œí¬í”Œë¡œìš° êµ¬ì¶• (1ì£¼)

#### 3.1 Airflow í™˜ê²½ ì„¤ì • (Windows)
```bash
# Airflow ì„¤ì¹˜
pip install apache-airflow

# Airflow ì´ˆê¸°í™” (Windows)
set AIRFLOW_HOME=C:\airflow
airflow db init
airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
```

#### 3.2 DAG (Directed Acyclic Graph) ì„¤ê³„
```python
# ì˜ˆì‹œ DAG ì½”ë“œ
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'data_scientist',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'delivery_data_pipeline',
    default_args=default_args,
    description='ë°°ë‹¬ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸',
    schedule_interval=timedelta(hours=1),
)

def extract_data():
    # ë°ì´í„° ì¶”ì¶œ ë¡œì§
    pass

def transform_data():
    # ë°ì´í„° ë³€í™˜ ë¡œì§
    pass

def load_data():
    # ë°ì´í„° ë¡œë“œ ë¡œì§
    pass

extract_task = PythonOperator(
    task_id='extract_data',
    python_callable=extract_data,
    dag=dag,
)

transform_task = PythonOperator(
    task_id='transform_data',
    python_callable=transform_data,
    dag=dag,
)

load_task = PythonOperator(
    task_id='load_data',
    python_callable=load_data,
    dag=dag,
)

extract_task >> transform_task >> load_task
```

### Phase 4: Redis + PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° êµ¬ì¶• (1ì£¼)

#### 4.1 Redis ì„¤ì • (Windows)
```bash
# Redis for Windows ì„¤ì¹˜
# https://github.com/microsoftarchive/redis/releases ì—ì„œ ë‹¤ìš´ë¡œë“œ
# ë˜ëŠ” Docker ì‚¬ìš©
docker run -d -p 6379:6379 redis:latest
```

#### 4.2 Redis ë°ì´í„° êµ¬ì¡° ì„¤ê³„
```python
import redis
import json

# Redis ì—°ê²°
r = redis.Redis(host='localhost', port=6379, db=0)

# ì‹¤ì‹œê°„ ì£¼ë¬¸ ë°ì´í„° ìºì‹±
def cache_order_data(order_data):
    r.setex(f"order:{order_data['order_id']}", 3600, json.dumps(order_data))

# ê³ ê° ì„¸ì…˜ ë°ì´í„° ì €ì¥
def store_customer_session(customer_id, session_data):
    r.hset(f"customer:{customer_id}", mapping=session_data)

# ì‹¤ì‹œê°„ í†µê³„ ë°ì´í„°
def update_realtime_stats(stats_data):
    r.hset("realtime_stats", mapping=stats_data)
```

#### 4.3 PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„
```sql
-- ì˜ˆì‹œ ìŠ¤í‚¤ë§ˆ
CREATE TABLE orders (
    order_id VARCHAR(50) PRIMARY KEY,
    customer_id VARCHAR(50),
    restaurant_id VARCHAR(50),
    order_amount DECIMAL(10,2),
    order_time TIMESTAMP,
    delivery_address TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE customers (
    customer_id VARCHAR(50) PRIMARY KEY,
    customer_name VARCHAR(100),
    phone_number VARCHAR(20),
    address TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE restaurants (
    restaurant_id VARCHAR(50) PRIMARY KEY,
    restaurant_name VARCHAR(100),
    category VARCHAR(50),
    rating DECIMAL(3,2),
    address TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE order_items (
    order_id VARCHAR(50),
    item_name VARCHAR(100),
    quantity INT,
    price DECIMAL(10,2),
    FOREIGN KEY (order_id) REFERENCES orders(order_id)
);
```

#### 4.4 ë°ì´í„° ì ì¬ ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ
```python
import psycopg2
import pandas as pd
import redis
import json

def load_data_to_db():
    # PostgreSQL ì—°ê²°
    conn = psycopg2.connect(
        host="localhost",
        database="delivery_db",
        user="postgres",
        password="password"
    )
    
    # Redis ì—°ê²°
    r = redis.Redis(host='localhost', port=6379, db=0)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('processed_data.csv')
    
    # PostgreSQLì— ì‚½ì…
    for _, row in df.iterrows():
        # INSERT ë¡œì§
        pass
    
    # Redisì— ìºì‹œ
    for _, row in df.iterrows():
        cache_data = {
            'order_id': row['order_id'],
            'amount': row['order_amount'],
            'timestamp': row['order_time']
        }
        r.setex(f"order:{row['order_id']}", 3600, json.dumps(cache_data))
    
    conn.close()
```

### Phase 5: ì›¹ ì„œë¹„ìŠ¤ ê°œë°œ (2ì£¼)

#### 5.1 Flask/FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°
```
web_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ templates/
â”œâ”€â”€ static/
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â””â”€â”€ main.py
```

#### 5.2 Redis í†µí•© ì›¹ ì„œë¹„ìŠ¤
```python
# ì˜ˆì‹œ FastAPI ì½”ë“œ
from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import redis
import json

app = FastAPI()

# Redis ì—°ê²°
redis_client = redis.Redis(host='localhost', port=6379, db=0)

@app.get("/")
async def home():
    return {"message": "ë°°ë‹¬ì˜ë¯¼ì¡± ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ"}

@app.get("/analytics/order-trends")
async def get_order_trends():
    # Redisì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ
    realtime_data = redis_client.hgetall("realtime_stats")
    # ì£¼ë¬¸ íŠ¸ë Œë“œ ë¶„ì„
    # ì‹œê°„ëŒ€ë³„, ìš”ì¼ë³„, ì›”ë³„ ì£¼ë¬¸ íŒ¨í„´
    pass

@app.get("/analytics/customer-segments")
async def get_customer_segments():
    # ê³ ê° ì„¸ë¶„í™” ë¶„ì„
    # RFM ë¶„ì„, ê³ ê° ìƒì•  ê°€ì¹˜ ë¶„ì„
    pass

@app.get("/analytics/restaurant-performance")
async def get_restaurant_performance():
    # ê°€ê²Œ ì„±ê³¼ ë¶„ì„
    # ë§¤ì¶œ, í‰ì , ì£¼ë¬¸ëŸ‰ ë¶„ì„
    pass

@app.get("/analytics/delivery-optimization")
async def get_delivery_optimization():
    # ë°°ë‹¬ ìµœì í™” ë¶„ì„
    # ë°°ë‹¬ ì‹œê°„, ê±°ë¦¬, ë¹„ìš© ë¶„ì„
    pass

@app.get("/cache/order/{order_id}")
async def get_cached_order(order_id: str):
    # Redisì—ì„œ ì£¼ë¬¸ ë°ì´í„° ì¡°íšŒ
    cached_data = redis_client.get(f"order:{order_id}")
    if cached_data:
        return json.loads(cached_data)
    else:
        raise HTTPException(status_code=404, detail="Order not found in cache")
```

#### 5.3 ëŒ€ì‹œë³´ë“œ êµ¬í˜„
- **ì£¼ë¬¸ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ**: ì‹œê°„ëŒ€ë³„, ìš”ì¼ë³„ ì£¼ë¬¸ íŒ¨í„´
- **ê³ ê° ë¶„ì„ ëŒ€ì‹œë³´ë“œ**: ê³ ê° ì„¸ë¶„í™”, ìƒì•  ê°€ì¹˜ ë¶„ì„
- **ê°€ê²Œ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ**: ë§¤ì¶œ, í‰ì , ì¸ê¸°ë„ ë¶„ì„
- **ë°°ë‹¬ ìµœì í™” ëŒ€ì‹œë³´ë“œ**: ë°°ë‹¬ ì‹œê°„, ê±°ë¦¬, ë¹„ìš© ë¶„ì„
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: Redisë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë°ì´í„° í‘œì‹œ

### Phase 6: Docker ì»¨í…Œì´ë„ˆí™” (1ì£¼)

#### 6.1 Dockerfile ì‘ì„±
```dockerfile
# ì˜ˆì‹œ Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 6.2 Docker Compose ì„¤ì • (Redis í¬í•¨)
```yaml
# docker-compose.yml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
      - kafka
  
  db:
    image: postgres:13
    environment:
      POSTGRES_DB: delivery_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
  
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

volumes:
  postgres_data:
  redis_data:
```

### Phase 7: Kubernetes ë°°í¬ (1ì£¼)

#### 7.1 Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì‘ì„±
```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: delivery-analytics
spec:
  replicas: 3
  selector:
    matchLabels:
      app: delivery-analytics
  template:
    metadata:
      labels:
        app: delivery-analytics
    spec:
      containers:
      - name: web-app
        image: delivery-analytics:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          value: "postgresql://postgres:password@db:5432/delivery_db"
        - name: REDIS_URL
          value: "redis://redis:6379"
```

```yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: delivery-analytics-service
spec:
  selector:
    app: delivery-analytics
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

#### 7.2 Helm Chart êµ¬ì„± (ì„ íƒì‚¬í•­)
```bash
# Helm Chart ìƒì„±
helm create delivery-analytics
```

### Phase 8: AWS í´ë¼ìš°ë“œ ë°°í¬ (1ì£¼)

#### 8.1 AWS ì„œë¹„ìŠ¤ ì„ íƒ
- **EC2**: ì›¹ ì„œë²„ í˜¸ìŠ¤íŒ…
- **RDS**: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤
- **ElastiCache**: Redis ìºì‹œ
- **EKS**: Kubernetes í´ëŸ¬ìŠ¤í„°
- **S3**: ë°ì´í„° ì €ì¥ì†Œ
- **CloudWatch**: ëª¨ë‹ˆí„°ë§

#### 8.2 AWS ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
```bash
# AWS CLI ì„¤ì •
aws configure

# EKS í´ëŸ¬ìŠ¤í„° ìƒì„±
eksctl create cluster --name delivery-cluster --region us-west-2

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
kubectl apply -f k8s/
```

## ğŸ“Š ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ê´€ì ì˜ ë¶„ì„ ê³¼ì œ

### 1. ê³ ê° í–‰ë™ ë¶„ì„
- **RFM ë¶„ì„**: Recency, Frequency, Monetary ë¶„ì„
- **ê³ ê° ìƒì•  ê°€ì¹˜ (CLV)**: ê³ ê°ë³„ ì˜ˆìƒ ìˆ˜ìµ ë¶„ì„
- **ê³ ê° ì„¸ë¶„í™”**: í–‰ë™ íŒ¨í„´ì— ë”°ë¥¸ ê³ ê° ê·¸ë£¹ ë¶„ë¥˜

### 2. ê°€ê²Œ ì„±ê³¼ ë¶„ì„
- **ë§¤ì¶œ ë¶„ì„**: ì‹œê°„ëŒ€ë³„, ìš”ì¼ë³„ ë§¤ì¶œ íŒ¨í„´
- **ë©”ë‰´ ë¶„ì„**: ì¸ê¸° ë©”ë‰´, ì¡°í•© ë¶„ì„
- **í‰ì  ë¶„ì„**: ê³ ê° ë§Œì¡±ë„ ë¶„ì„

### 3. ë°°ë‹¬ ìµœì í™” ë¶„ì„
- **ë°°ë‹¬ ì‹œê°„ ë¶„ì„**: í‰ê·  ë°°ë‹¬ ì‹œê°„, ì§€ì—° ìš”ì¸ ë¶„ì„
- **ë°°ë‹¬ ê±°ë¦¬ ë¶„ì„**: ê±°ë¦¬ë³„ ë°°ë‹¬ë£Œ, ì‹œê°„ ë¶„ì„
- **ë°°ë‹¬ ê²½ë¡œ ìµœì í™”**: íš¨ìœ¨ì ì¸ ë°°ë‹¬ ê²½ë¡œ ì œì•ˆ

### 4. ì˜ˆì¸¡ ëª¨ë¸ë§
- **ì£¼ë¬¸ëŸ‰ ì˜ˆì¸¡**: ì‹œê°„ëŒ€ë³„, ìš”ì¼ë³„ ì£¼ë¬¸ëŸ‰ ì˜ˆì¸¡
- **ê³ ê° ì´íƒˆ ì˜ˆì¸¡**: ë‹¤ìŒ ì£¼ë¬¸ ê°€ëŠ¥ì„± ì˜ˆì¸¡
- **ê°€ê²Œ ì„±ê³¼ ì˜ˆì¸¡**: ë§¤ì¶œ, í‰ì  ì˜ˆì¸¡

### 5. ì‹¤ì‹œê°„ ë¶„ì„ (Redis í™œìš©)
- **ì‹¤ì‹œê°„ ì£¼ë¬¸ ëª¨ë‹ˆí„°ë§**: í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì£¼ë¬¸ ì¶”ì 
- **ì‹¤ì‹œê°„ í†µê³„**: í˜„ì¬ ì‹œê°„ì˜ ì£¼ë¬¸ëŸ‰, ë§¤ì¶œ ë“±
- **ì‹¤ì‹œê°„ ì•Œë¦¼**: íŠ¹ì • ì¡°ê±´ ë‹¬ì„± ì‹œ ì•Œë¦¼

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ í•™ìŠµ ê°€ì´ë“œ

### í•„ìˆ˜ ê¸°ìˆ 
1. **Python**: ë°ì´í„° ë¶„ì„, ì›¹ ê°œë°œ
2. **SQL**: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬, ë°ì´í„° ê´€ë¦¬
3. **Redis**: ìºì‹±, ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
4. **Docker**: ì»¨í…Œì´ë„ˆí™”
5. **Kubernetes**: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
6. **AWS**: í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤

### ì¶”ê°€ í•™ìŠµ ê¶Œì¥ì‚¬í•­
1. **Apache Spark**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
2. **Elasticsearch**: ë¡œê·¸ ë¶„ì„
3. **Grafana**: ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
4. **Prometheus**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘

## ğŸ“ˆ ì„±ê³¼ ì¸¡ì • ì§€í‘œ

### ê¸°ìˆ ì  ì§€í‘œ
- ë°ì´í„° ì²˜ë¦¬ ì†ë„ (records/second)
- API ì‘ë‹µ ì‹œê°„ (ms)
- Redis ìºì‹œ íˆíŠ¸ìœ¨ (%)
- ì‹œìŠ¤í…œ ê°€ìš©ì„± (%)
- ì—ëŸ¬ìœ¨ (%)

### ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ
- ì¼ì¼ í™œì„± ì‚¬ìš©ì ìˆ˜
- í‰ê·  ì„¸ì…˜ ì‹œê°„
- í˜ì´ì§€ ë·° ìˆ˜
- ì‚¬ìš©ì ë§Œì¡±ë„
- ì‹¤ì‹œê°„ ì£¼ë¬¸ ì²˜ë¦¬ëŸ‰

## ğŸš€ í”„ë¡œì íŠ¸ ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„

### 1. ê³ ê¸‰ ë¶„ì„
- **ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸**: ì¶”ì²œ ì‹œìŠ¤í…œ, ì´ìƒ íƒì§€
- **ì‹¤ì‹œê°„ ë¶„ì„**: ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì‹¤ì‹œê°„ ì²˜ë¦¬
- **A/B í…ŒìŠ¤íŠ¸**: ê¸°ëŠ¥ ê°œì„  íš¨ê³¼ ì¸¡ì •

### 2. í™•ì¥ì„± ê°œì„ 
- **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤**: ì„œë¹„ìŠ¤ ë¶„ë¦¬
- **ë¡œë“œ ë°¸ëŸ°ì‹±**: íŠ¸ë˜í”½ ë¶„ì‚°
- **ìºì‹±**: Redisë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”

### 3. ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜
- **ë¡œê¹…**: ì‹œìŠ¤í…œ ë¡œê·¸ ìˆ˜ì§‘
- **ì•Œë¦¼**: ì¥ì•  ì•Œë¦¼ ì‹œìŠ¤í…œ
- **ë°±ì—…**: ë°ì´í„° ë°±ì—… ì „ëµ

## ğŸ’¡ í•™ìŠµ íŒ

### 1. ë‹¨ê³„ë³„ ì ‘ê·¼
- ê° ë‹¨ê³„ë¥¼ ì™„ë£Œí•œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
- ê° ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì¶©ë¶„íˆ í•´ê²° í›„ ì§„í–‰

### 2. ë¬¸ì„œí™”
- ì½”ë“œ ì£¼ì„ ì‘ì„±
- README íŒŒì¼ ì—…ë°ì´íŠ¸
- ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±

### 3. ì»¤ë®¤ë‹ˆí‹° í™œìš©
- GitHub: ì½”ë“œ ê³µìœ  ë° í”¼ë“œë°±
- Stack Overflow: ë¬¸ì œ í•´ê²°
- ê¸°ìˆ  ë¸”ë¡œê·¸: í•™ìŠµ ë‚´ìš© ì •ë¦¬

### 4. ì‹¤ë¬´ ê²½í—˜
- ì‹¤ì œ ê¸°ì—… í”„ë¡œì íŠ¸ì™€ ìœ ì‚¬í•œ í™˜ê²½ êµ¬ì„±
- ì‹¤ì œ ë°ì´í„°ë¡œ ì‘ì—…í•˜ì—¬ ì‹¤ë¬´ ê°ê° ìŠµë“
- íŒ€ í”„ë¡œì íŠ¸ë¡œ ì§„í–‰í•˜ì—¬ í˜‘ì—… ê²½í—˜

## ğŸ“š ì°¸ê³  ìë£Œ

### ë„ì„œ
- "ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í•¸ë“œë¶" - Jake VanderPlas
- "Designing Data-Intensive Applications" - Martin Kleppmann
- "Kubernetes in Action" - Marko LukÅ¡a
- "Redis in Action" - Josiah L. Carlson

### ì˜¨ë¼ì¸ ê°•ì˜
- Coursera: Data Science Specialization
- Udemy: Apache Kafka Series
- AWS Training: Cloud Practitioner
- Redis University: Redis Courses

### ê¸°ìˆ  ë¬¸ì„œ
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Redis Documentation](https://redis.io/documentation)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [AWS Documentation](https://docs.aws.amazon.com/)

---

**ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë©´ì„œ ì‹¤ì œ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì˜ ì—…ë¬´ í™˜ê²½ì„ ì²´í—˜í•˜ê³ , í˜„ëŒ€ì ì¸ ê¸°ìˆ  ìŠ¤íƒì„ ìŠµë“í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ë‹¨ê³„ì—ì„œ ì–´ë ¤ì›€ì´ ìˆìœ¼ë©´ ì¶©ë¶„íˆ í•™ìŠµí•˜ê³  í•´ê²°í•œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”!** ğŸš€
